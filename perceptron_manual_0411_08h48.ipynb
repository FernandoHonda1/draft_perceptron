{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# primeiramente, crio três conjuntos de dados, sendo os dois primeiros, 'df0' e 'df1', casos linearmente \n",
    "# separáveis, e 'df2', não lineamente separável\n",
    "\n",
    "# dados linearmente separáveis\n",
    "df0 = pd.DataFrame([[0, 0, 0, 0], \n",
    "                    [1, 0, 0, 0],\n",
    "                    [1, 1, 0, 1],\n",
    "                    [1, 0, 1, 1],\n",
    "                    [1, 1, 1, 1]],\n",
    "                    columns = ['x0', 'x1', 'x2', 'y'])\n",
    "\n",
    "# dados linearmente separáveis\n",
    "df1 = pd.DataFrame([[0, 0, 0, 0, 0],\n",
    "                    [0, 0, 1, 0, 0],\n",
    "                    [1, 0, 0, 0, 0],\n",
    "                    [1, 1, 0, 0, 0],\n",
    "                    [1, 0, 1, 0, 0],\n",
    "                    [1, 1, 1, 0, 1],\n",
    "                    [1, 0, 1, 1, 1],\n",
    "                    [1, 1, 1, 1, 1]],\n",
    "                    columns = ['x0', 'x1', 'x2', 'x3', 'y'])\n",
    "\n",
    "# dados NÃO linearmente separáveis\n",
    "df2 = pd.DataFrame([[0, 0, 0, 1],\n",
    "                    [0, 1, 0, 0],\n",
    "                    [0, 0, 1, 0],\n",
    "                    [1, 0, 1, 0],\n",
    "                    [1, 1, 1, 1]],\n",
    "                    columns = ['x0', 'x1', 'x2', 'y'])\n",
    "\n",
    "# semente (para obtenção de coeficientes 'iniciais')\n",
    "seed = 123\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a função 'perceptron()' é a que, de fato, trabalha como um perceptron, as funções 'get_errors()' e \n",
    "# 'coefficient_optimization()' são executadas em 'loop', pela função 'perceptron()'\n",
    "\n",
    "# a seguinte função desencadeia o primeiro processo empregado no perceptron; a obtenção de um y-chapéu para cada\n",
    "# observação, através do somatório de coeficientes multiplicados pelas suas respectivas variáveis, em seguida,\n",
    "# é feita a limiarização deste valor (função de ativação), os dois valores, limiarizado e não limiarizado são\n",
    "# são armzenados (o valor limiarizado é comparado ao valor verdadeiro, já o valor não limiarizado é utilizado\n",
    "# no processo de otimização) para cada observação, acompanhados do valor verdadeiro, para que, posteriormente, \n",
    "# possamos 'rastrear' erros e acertos (pelo índice da observação, que também é armazenado, por este motivo, \n",
    "# é importante que o dataframe contendo os dados tenha seu índice ordenado e possua um 'range' iniciando em 0,\n",
    "# com 'step' de 1), o retorno da função consiste em três variáveis, sendo a primeira, o índice da primeira\n",
    "# observação prevista incorretamente (em vez de implementar uma condição de parada 'instantânea', obtenho todas\n",
    "# as predições e depois encontro a primeira, fiz o processo desta forma porque me pareceu mais fácil, por mais\n",
    "# que resulte em trabalho desnecessário), no caso de todas as previsões estarem corretas, esta variável é \n",
    "# 'None', além disso a função também retorna os coeficientes (coefficients) e o dicinário (pred_dict) contendo\n",
    "# as predições e valores esperados; estes são algo como 'variáveis globais', que sofrem consultas e alterações, \n",
    "# ao decorrer do processo\n",
    "def get_errors(feature_matrix, label, coefficients, threshold, upper, lower): \n",
    "    \n",
    "    '''Params:\n",
    "       feature_matrix -> variáveis explicativas\n",
    "       label -> valores verdadeiros\n",
    "       coefficients -> vetor de coeficientes\n",
    "       threshold -> limiar da função de ativação\n",
    "       upper -> limite superior (valor assumido por y-chapéu, caso esteja acima de 'threshold')\n",
    "       lower -> limite inferior (valor assumido por y-chapéu, caso esteja abaixo de 'threshold')'''\n",
    "    \n",
    "    count = 0\n",
    "    pred_dict = {}\n",
    "    for n in range(len(coefficients)): # calculando e limiarizando predições \n",
    "        predicted = round(sum(feature_matrix.iloc[n] * coefficients))\n",
    "        \n",
    "        if predicted >= threshold:\n",
    "            pred_aux = upper\n",
    "        else:\n",
    "            pred_aux = lower\n",
    "        \n",
    "        pred_dict[count] = {'predicted' : predicted, 'actual' : label.iloc[n], 'pred_aux': pred_aux}\n",
    "        count += 1\n",
    "    \n",
    "    # comparando predições limiarizadas com valores verdadeiros        \n",
    "    error_ids = [key for key in pred_dict.keys() if pred_dict[key]['pred_aux'] != pred_dict[key]['actual']]\n",
    "        \n",
    "    if len(error_ids) == 0: # condição de parada (convergência)\n",
    "        return None, coefficients, pred_dict      \n",
    "    else:\n",
    "        return min(error_ids), coefficients, pred_dict \n",
    "\n",
    "# esta função ajusta os coeficientes, de acordo com a primeira previsão incorreta, da última época, aqui\n",
    "# também é feita a interpretação de uma das variáveis retornadas pela função anterior, com base nisso, a função\n",
    "# retorna a condição de parada da próxima função (que realmente executa o 'loop'; esta função, da mesma forma \n",
    "# que a anterior, é uma etapa 'intermediária'), nesta função, introduzimos 'learning_rate', entretanto, não\n",
    "# 'alimentamos' esta função diretamente, definimos o parâmetro na função seguinte, que engloba esta e a anterior\n",
    "def coefficient_optimization(error_id, coef_list, pred_dict, learning_rate, feature_matrix, label): \n",
    "    \n",
    "    if error_id == None: # interpreta condição de parada implementada retornada pela função anterior\n",
    "        return 'stop', coef_list\n",
    "\n",
    "    bad_row = feature_matrix.iloc[error_id] # <- aqui, acesso cada variável explicativa da observação, cuja \n",
    "                                            #    previsão falhou\n",
    "    \n",
    "    # a seguinte lista passará a ser o novo vetor de coeficientes, estes obtidos através do ajuste dos\n",
    "    # ceoficientes anteriores, com base na primeira predição incorreta\n",
    "    new_coefs = [coef_list[n]+learning_rate*bad_row[n]*(label.iloc[error_id]-pred_dict[error_id]['predicted'])\\\n",
    "                  for n in range(len(bad_row))]\n",
    "    # coef_list[n] <- coeficiente, acessado 'posicionalmente', no vetor\n",
    "    # bad_row[n] <- representa a variável explicativa da observação\n",
    "    # (label.iloc[error_id] - pred_dict[error_id]['predicted']) <- subtração do valor previsto, não limiarizado,\n",
    "                                                                #  do valor verdadeiro\n",
    "                \n",
    "    return 'go', new_coefs\n",
    "\n",
    "def perceptron(feature_matrix, label, coefficients, learning_rate, threshold, upper, lower, max_epoch):\n",
    "    \n",
    "    run = 'go'\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        if run == 'go':\n",
    "            \n",
    "            error_id, coef_list, pred_dict = get_errors(feature_matrix, label, coefficients, \n",
    "                                                        threshold, upper, lower)\n",
    "            \n",
    "            run, new_coefs = coefficient_optimization(error_id, coef_list, pred_dict,\n",
    "                                                     learning_rate, feature_matrix, label) \n",
    "            coefficients = new_coefs # redefinindo coeficientes\n",
    "            epoch += 1\n",
    "            # condição de parada (por convergência ou exaustão)\n",
    "            if epoch == max_epoch and run != 'stop':\n",
    "                return new_coefs, 'max_epoch reached, no convergence'\n",
    "\n",
    "            elif epoch != max_epoch and run == 'stop':  \n",
    "                return new_coefs, 'convergence achieved'\n",
    "\n",
    "            elif epoch == max_epoch and run == 'stop':\n",
    "                return new_coefs, 'max_epoch reached, convergence achieved'\n",
    "            \n",
    "# à partir daqui, exemplos de uso da função 'perceptron()' (em 'df0', 'df1', 'df2')\n",
    "max_epoch = 25\n",
    "learning_rate = 0.1\n",
    "threshold = 0.5\n",
    "upper = 1\n",
    "lower = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous coefficients: [-0.8959999999999999, -0.8259999999999998, -0.18599999999999928]\n",
      "updated coefficients:  [0.30400000000000016, 0.3740000000000002, -0.18599999999999928]\n",
      "report:                convergence achieved\n"
     ]
    }
   ],
   "source": [
    "# ajuste a 'df0' (linearmente separável)\n",
    "\n",
    "# coeficientes de df0 não otimizados (gerados 'aleatoriamente')\n",
    "coefficients0 = random.choices(population = np.arange(start = -1, stop = 1, step = 0.001), k = 3)\n",
    "print(f'previous coefficients: {coefficients0}')\n",
    "\n",
    "coefs0, report0 = perceptron(coefficients = coefficients0, threshold = threshold, upper = upper, \n",
    "                             lower = lower, learning_rate = learning_rate,\n",
    "                             feature_matrix = df0[['x0', 'x1', 'x2']], label = df0['y'],\n",
    "                             max_epoch = max_epoch)\n",
    "\n",
    "print(f'updated coefficients:  {coefs0}')\n",
    "print(f'report:                {report0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous coefficients: [-0.7849999999999998, 0.8020000000000016, -0.9239999999999999, 0.07200000000000095]\n",
      "updated coefficients:  [-0.7849999999999998, 0.8020000000000016, -0.9239999999999999, 0.07200000000000095]\n",
      "report:                convergence achieved\n"
     ]
    }
   ],
   "source": [
    "# ajuste a 'df1' (linearmente separável)\n",
    "\n",
    "# coeficientes de df1 não otimizados (gerados 'aleatoriamente')\n",
    "coefficients1 = random.choices(population = np.arange(start = -1, stop = 1, step = 0.001), k = 4)\n",
    "print(f'previous coefficients: {coefficients1}')\n",
    "\n",
    "coefs1, report1 = perceptron(coefficients = coefficients1, threshold = threshold, upper = upper,\n",
    "                             lower = lower, learning_rate = learning_rate,\n",
    "                             feature_matrix = df1[['x0', 'x1', 'x2', 'x3']], \n",
    "                             label = df1['y'], max_epoch = max_epoch)\n",
    "\n",
    "print(f'updated coefficients:  {coefs1}')\n",
    "print(f'report:                {report1}')\n",
    "\n",
    "# não foram necessários ajustes, mas alterando a 'seed', estes coeficientes, muito provavelmente serão \n",
    "# (testei as seeds 777 e 9000, ambas resultam em ajuste sutil no terceiro coeficiente, a seed 0 também \n",
    "# resulta em um conjunto de coeficientes que não necessita de ajustes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous coefficients: [-0.3359999999999994, 0.7040000000000015, -0.6809999999999997]\n",
      "updated coefficients:  [-0.3359999999999994, 0.7040000000000015, -0.6809999999999997]\n",
      "report:                max_epoch reached, no convergence\n"
     ]
    }
   ],
   "source": [
    "# ajuste a df2 (NÃO linearmente separável)\n",
    "\n",
    "# coeficientes de df2 não otimizados (gerados 'aleatoriamente')\n",
    "coefficients2 = random.choices(population = np.arange(start = -1, stop = 1, step = 0.001), k = 3)\n",
    "print(f'previous coefficients: {coefficients2}')\n",
    "\n",
    "coefs2, report2 = perceptron(coefficients = coefficients2, threshold = threshold, upper = upper,\n",
    "                             lower = lower, learning_rate = learning_rate, \n",
    "                             feature_matrix = df2[['x0', 'x1', 'x2']], label = df2['y'],\n",
    "                             max_epoch = max_epoch)\n",
    "\n",
    "print(f'updated coefficients:  {coefs2}')\n",
    "print(f'report:                {report2}')\n",
    "\n",
    "# não otimiza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
